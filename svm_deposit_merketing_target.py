# -*- coding: utf-8 -*-
"""SVM - Deposit Merketing Target.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qrXDzhS83DSI0NAy5IhXmi423lpwlZYx

#Data Loading
"""

# install kaggle
import requests
URL = "https://raw.githubusercontent.com/rezaafaisal/source/main/kaggle.json"
response = requests.get(URL)
open("kaggle.json", "wb").write(response.content)

!ls -lha kaggle.json
!pip install -q kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# unduh dataset kaggle (zip)
!kaggle datasets download -d prakharrathi25/banking-dataset-marketing-targets

# import library yang digunakan
import shutil
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import  OneHotEncoder

# ekstrak dataset
shutil.unpack_archive('/content/banking-dataset-marketing-targets.zip', 'dataset')

# memuat data
train_df = pd.read_csv("/content/dataset/train.csv", sep=";",)
test_df = pd.read_csv("/content/dataset/test.csv", sep=";")

# gabung data train dan
merged_df = pd.concat([train_df, test_df], ignore_index=False, sort=False)

"""#Exploratory Data Anylisis"""

# preview data
merged_df.head()

# cek tipe data
merged_df.info()

# cek dimensi awal
merged_df.shape

"""## Menangani Missing Value"""

# cek missing value
merged_df.isna().sum()

# cek data duplikat
merged_df.duplicated().sum()

# hapus data duplicate
merged_df = merged_df.drop_duplicates()

merged_df.shape

"""##Menangani Outlier"""

merged_df.describe()

# cek outlier fitur balance
plt.figure(figsize=(5,3))
sns.boxplot(x=merged_df.balance)

# cek outlier fitur duration
plt.figure(figsize=(5,3))
sns.boxplot(x=merged_df.duration)

# menghapus outlier
outlier_columns = ['balance', 'duration']

Q1 = merged_df[outlier_columns].quantile(0.25)
Q3 = merged_df[outlier_columns].quantile(0.75)

IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

new_df = merged_df[~((merged_df<lower_bound)|(merged_df>upper_bound)).any(axis=1)]

new_df.shape

new_df.head()

"""##Univariate Analysis"""

# menentukan feature numerik dan kategorik
numerical_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']
categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'y']

# menampilkan semua categorical
for categorical_feature in categorical_features:
  count = new_df[categorical_feature].value_counts()
  percent = 100*new_df[categorical_feature].value_counts(normalize=True)
  df = pd.DataFrame({
      'jumlah sampel': count,
      'persentase': percent.round(1)
  })
  print(f"{categorical_feature}")
  print(df)

  plt.figure(figsize=(4,3))
  count.plot(kind='bar', title=categorical_feature)
  plt.show()
  print("\n")

# menghitung numerik
new_df.hist(bins=50, figsize=(20, 15))
plt.show()

"""## Multivariate Analysis"""

categorical_features = new_df.select_dtypes(include='object').columns.to_list()

for column in categorical_features:
  sns.catplot(x=column, kind='count', dodge=False, palette="Set3", hue='y', height=3, aspect=2, data=new_df)
  plt.xlabel(column.capitalize())
  plt.xticks(rotation=45)
  plt.show()
  print("\n")

# mengecek korelasi antar fitur
new_df.replace({
    'y': {'yes': 1, 'no':0}
}, inplace=True)

plt.figure(figsize=(7, 3))
sns.heatmap(data=new_df.corr().round(2), annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Korelasi Untuk Fitur Numerik", size=20)

"""#Data Preparation"""

# hapus kolom age dan day karena korelasinya kecil
new_df.drop(['age', 'day'], axis=1, inplace=True)

# ganti tipe data menjadi binominal
new_df.replace({
    'default': {'yes': 1, 'no': 0},
    'housing': {'yes': 1, 'no': 0},
    'loan': {'yes': 1, 'no': 0},
    }, inplace=True)

# ganti nama bulan menjadi angka
new_df.replace({
    'month': {
        'jan': 1,
        'feb': 2,
        'mar': 3,
        'apr': 4,
        'may': 5,
        'jun': 6,
        'jul': 7,
        'aug': 8,
        'sep': 9,
        'oct': 10,
        'nov': 11,
        'dec': 12,
    }
}, inplace=True)

new_df.head()

encode_columns = ['job', 'marital', 'education', 'contact', 'poutcome']
encoder = OneHotEncoder(sparse_output=False, drop='first')
encoded_data = encoder.fit_transform(new_df[encode_columns])
encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(encode_columns))

new_encoded_df = pd.concat([new_df.reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)

new_encoded_df.drop(encode_columns, axis=1, inplace=True)

print(new_encoded_df.shape)

pd.set_option('display.max_columns', None)
new_encoded_df.tail()

"""#Model Development"""

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# bagi data latih dan data uji
x = new_encoded_df.drop(['y'], axis=1)
y = new_encoded_df['y']


x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

print(f"Total data latih : {len(x_train)}")
print(f"Total data uji : {len(x_test)}")

"""##Algoritma SVM"""

# latih model
svm_classifier = SVC(kernel='sigmoid', random_state=42, probability=True, verbose=True)
svm_classifier.fit(x_train, y_train)

# akurasi
predict = svm_classifier.predict(x_test)

accuracy = accuracy_score(y_test, predict)
print(f"Akurasi : {accuracy}")

# classification report
class_report = classification_report(y_test, predict)
print(class_report)

# konfusion matriks
conf = confusion_matrix(y_test, predict)

plt.figure(figsize=(3,3))
sns.heatmap(conf, annot=True, fmt='d', cmap='crest', cbar=False)

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

"""## Algoritma Naural Network"""

from sklearn.neural_network import MLPClassifier

nn_classifier = MLPClassifier(hidden_layer_sizes=12, activation='relu', n_iter_no_change=30, solver='adam')
nn_classifier.fit(x_train, y_train)

# akurasi
predict = nn_classifier.predict(x_test)

accuracy = accuracy_score(y_test, predict)
print(f"Akurasi : {accuracy}")

# classification report
class_report = classification_report(y_test, predict)
print(class_report)

# konfusion matriks
conf = confusion_matrix(y_test, predict)

plt.figure(figsize=(3,3))
sns.heatmap(conf, annot=True, fmt='d', cmap='crest', cbar=False)

# Add labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')